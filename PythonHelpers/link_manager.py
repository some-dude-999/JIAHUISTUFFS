#!/usr/bin/env python3
"""
Automated Link Manager for GitHub Pages
Scans repository for HTML files and generates/updates LINK.txt with GitHub Pages URLs
"""

import os
import subprocess
import urllib.parse
from pathlib import Path


def get_repo_info():
    """Extract repository owner and name from git remote"""
    try:
        remote_url = subprocess.check_output(
            ['git', 'config', '--get', 'remote.origin.url'],
            stderr=subprocess.DEVNULL
        ).decode('utf-8').strip()

        # Handle both HTTPS and SSH URLs
        if remote_url.startswith('https://'):
            # https://github.com/owner/repo.git
            parts = remote_url.replace('https://github.com/', '').replace('.git', '').split('/')
        elif remote_url.startswith('git@'):
            # git@github.com:owner/repo.git
            parts = remote_url.replace('git@github.com:', '').replace('.git', '').split('/')
        elif remote_url.startswith('http://') and '/git/' in remote_url:
            # http://local_proxy@127.0.0.1:44774/git/owner/repo
            git_part = remote_url.split('/git/')[-1]
            parts = git_part.replace('.git', '').split('/')
        else:
            return None, None

        if len(parts) >= 2:
            return parts[0], parts[1]
        return None, None
    except:
        return None, None


def find_html_files(root_dir):
    """Find all HTML files in the repository"""
    html_files = []
    root_path = Path(root_dir)

    for file_path in root_path.rglob('*.html'):
        # Skip files in .git directory
        if '.git' in file_path.parts:
            continue

        # Get relative path from root
        rel_path = file_path.relative_to(root_path)
        html_files.append(str(rel_path))

    return sorted(html_files)


def load_existing_descriptions(link_file):
    """Load existing descriptions from LINK.txt"""
    descriptions = {}

    if not os.path.exists(link_file):
        return descriptions

    try:
        with open(link_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line.startswith('http'):
                    # Split URL and description
                    parts = line.split(' - ', 1)
                    if len(parts) == 2:
                        url = parts[0].strip()
                        desc = parts[1].strip()
                        # Extract filename from URL for matching
                        descriptions[url] = desc
    except Exception as e:
        print(f"Warning: Could not read existing LINK.txt: {e}")

    return descriptions


def generate_github_pages_url(owner, repo, file_path):
    """Generate GitHub Pages URL for a file"""
    # URL encode the path components while preserving /
    path_parts = file_path.split('/')
    encoded_parts = [urllib.parse.quote(part) for part in path_parts]
    encoded_path = '/'.join(encoded_parts)

    return f"https://{owner}.github.io/{repo}/{encoded_path}"


def update_link_file(owner, repo, html_files, link_file='LINK.txt'):
    """Update LINK.txt with GitHub Pages URLs"""

    # Load existing descriptions
    existing_descriptions = load_existing_descriptions(link_file)

    # Generate new content
    lines = [
        f"# GitHub Pages Links for {owner}/{repo}",
        "# Auto-generated by PythonHelpers/link_manager.py",
        ""
    ]

    for html_file in html_files:
        url = generate_github_pages_url(owner, repo, html_file)

        # Check if we have an existing description for this URL
        if url in existing_descriptions:
            description = existing_descriptions[url]
        else:
            # Generate a placeholder description
            filename = os.path.basename(html_file)
            description = f"[Add description for {filename}]"

        lines.append(f"{url} - {description}")

    # Write to file
    with open(link_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines) + '\n')

    print(f"‚úÖ Updated {link_file} with {len(html_files)} HTML files")
    return len(html_files)


def main():
    """Main function"""
    print("üîó Running Link Manager...")

    # Get repository info
    owner, repo = get_repo_info()

    if not owner or not repo:
        print("‚ùå Error: Could not determine repository owner/name from git remote")
        print("   Make sure you're in a git repository with a remote named 'origin'")
        return 1

    print(f"üì¶ Repository: {owner}/{repo}")

    # Find HTML files
    html_files = find_html_files('.')

    if not html_files:
        print("‚ö†Ô∏è  No HTML files found in repository")
        return 0

    print(f"üîç Found {len(html_files)} HTML files:")
    for f in html_files:
        print(f"   - {f}")

    # Update LINK.txt
    count = update_link_file(owner, repo, html_files)

    print(f"\n‚ú® Done! Updated LINK.txt with {count} entries")
    print("   Review LINK.txt and update placeholder descriptions as needed")

    return 0


if __name__ == '__main__':
    exit(main())
